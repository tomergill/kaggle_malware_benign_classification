import xgboost as xgb
import pandas as pd
from os import getcwd
from time import time
import sys
import numpy as np
'''import pandas as pd
from sklearn.tree import DecisionTreeClassifier'''
from utils import get_all_files_features_and_labels
from sklearn.model_selection import train_test_split

def learn_with_XGBClassifier(train_data, train_lbl, test_files, test_lbl, lr=0.65,n_esti=5,seed=123):
    train_time = time()
    xg_cl = xgb.XGBClassifier(objective='multi:softmax', num_class= 10, learning_rate=lr,
                                    n_estimators=n_esti, seed=seed)
    xg_cl.fit(train_data, train_lbl)
    train_time = time() - train_time
    test_time = time()
    preds = xg_cl.predict(test_files)
    test_time = time() - test_time
    accuracy = float(np.sum(preds == test_lbl)) / test_lbl.shape[0]
    return {"train time: ": train_time, "test time: ": test_time, "accuracy: ": accuracy*100}

def learn_with_dt(train_files, train_lbl, test_file, test_lbl):
    train_time = time()
    xg_dt = DecisionTreeClassifier()
    xg_dt = xg_dt.fit(train_files, train_lbl)
    train_time = time() - train_time
    test_time = time()
    preds = xg_dt.predict(test_file)
    test_time = time() - test_time
    accuracy = float(np.sum(preds == test_lbl)) / test_lbl.shape[0]
    return {"train time: ": train_time, "test time: ": test_time, "accuracy: ": accuracy*100}


def learn_with_cv(X,Y):
    churn_dmatrix = xgb.DMatrix(X,Y)
    params = {"objective": "multi:softmax", "max_depth": 4, "num_class":10}
    cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=6, num_boost_round=30,
                       metrics="merror", as_pandas=True)
    return ((1 - cv_results["test-merror-mean"]).iloc[-1])





def main():
    print("start processing input")
    features, labels, ngrams_sets, i2ngram, ngram2i, labels_dict = get_all_files_features_and_labels("./files/train50", "./files/benign50", [4])
    print(ngrams_sets)
    print("--------------------------")
    print(i2ngram)
    print("--------------------------")
    print(ngram2i)
    X, Y = np.array(features), np.array(labels)
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=111)
    print("start learning...")
    print (learn_with_XGBClassifier(X_train, y_train, X_test, y_test))
    pass
    #print("strat learning cv")
    #print(learn_with_cv(X,Y)*100)

if __name__ == "__main__":
    main()