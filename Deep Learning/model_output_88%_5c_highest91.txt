/home/user/.local/lib/python2.7/site-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 1 which
    has less than 75% of the memory or cores of GPU 0. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Train examples: 6051  |  Validation examples: 1152
Training for 15 epochs
Training with Adam using 0.001 learning rate
Batch Normalization set to False
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

########## epoch #1 ##########
gone over 5 batches / 122 with 30.0% train accuracy and 1.68839776611 loss in 74.9436569214s
gone over 10 batches / 122 with 47.8% train accuracy and 1.38725227356 loss in 83.6240940094s
gone over 15 batches / 122 with 57.2% train accuracy and 1.19778812663 loss in 105.193976879s
gone over 20 batches / 122 with 61.2% train accuracy and 1.08685655212 loss in 118.411695957s
gone over 25 batches / 122 with 63.84% train accuracy and 1.01142268829 loss in 132.481114864s
gone over 30 batches / 122 with 66.0666666667% train accuracy and 0.945654061635 loss in 144.594771862s
gone over 35 batches / 122 with 68.0571428571% train accuracy and 0.895795765468 loss in 157.302624941s
gone over 40 batches / 122 with 69.5% train accuracy and 0.859136275291 loss in 168.695563078s
gone over 45 batches / 122 with 70.5777777778% train accuracy and 0.823054715474 loss in 211.768432856s
gone over 50 batches / 122 with 71.68% train accuracy and 0.796385243225 loss in 224.502014875s
gone over 55 batches / 122 with 72.6181818182% train accuracy and 0.772874785683 loss in 236.197977066s
gone over 60 batches / 122 with 73.2% train accuracy and 0.752600310008 loss in 249.649328947s
gone over 65 batches / 122 with 74.0307692308% train accuracy and 0.728782718365 loss in 264.464951992s
gone over 70 batches / 122 with 74.8285714286% train accuracy and 0.711594284603 loss in 288.699977875s
gone over 75 batches / 122 with 75.68% train accuracy and 0.68846953481 loss in 302.047111988s
gone over 80 batches / 122 with 76.425% train accuracy and 0.66685701704 loss in 332.369859934s
gone over 85 batches / 122 with 76.8705882353% train accuracy and 0.6522000517 loss in 344.973458052s
gone over 90 batches / 122 with 77.2888888889% train accuracy and 0.642466179318 loss in 356.91249299s
gone over 95 batches / 122 with 77.7894736842% train accuracy and 0.628568122864 loss in 366.722522974s
gone over 100 batches / 122 with 78.5% train accuracy and 0.61251139183 loss in 387.352108002s
gone over 105 batches / 122 with 78.8380952381% train accuracy and 0.60396898197 loss in 397.782232046s
gone over 110 batches / 122 with 79.1090909091% train accuracy and 0.595109531576 loss in 426.92435503s
gone over 115 batches / 122 with 79.4782608696% train accuracy and 0.583392781963 loss in 446.639824867s
gone over 120 batches / 122 with 79.7333333333% train accuracy and 0.573698046525 loss in 457.888755083s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  1  , 624.57295 ,    0.571213    ,   79.838043   %,   0.453332   ,  84.722222  %

########## epoch #2 ##########
gone over 5 batches / 122 with 90.0% train accuracy and 0.286947853088 loss in 52.9895319939s
gone over 10 batches / 122 with 91.8% train accuracy and 0.243991420746 loss in 66.8232460022s
gone over 15 batches / 122 with 92.1333333333% train accuracy and 0.250430366516 loss in 86.976806879s
gone over 20 batches / 122 with 92.5% train accuracy and 0.247912687302 loss in 96.9921188354s
gone over 25 batches / 122 with 92.56% train accuracy and 0.245754405212 loss in 120.904124022s
gone over 30 batches / 122 with 92.8666666667% train accuracy and 0.232369083881 loss in 134.389482021s
gone over 35 batches / 122 with 93.2% train accuracy and 0.219811215128 loss in 156.802547932s
gone over 40 batches / 122 with 92.9% train accuracy and 0.222891952634 loss in 167.651096821s
gone over 45 batches / 122 with 93.2% train accuracy and 0.217977728208 loss in 201.704077005s
gone over 50 batches / 122 with 93.44% train accuracy and 0.212603691387 loss in 212.497735977s
gone over 55 batches / 122 with 93.6363636364% train accuracy and 0.207018339591 loss in 246.835183859s
gone over 60 batches / 122 with 93.6% train accuracy and 0.207462673903 loss in 259.638667822s
gone over 65 batches / 122 with 93.6923076923% train accuracy and 0.205515172885 loss in 269.819691896s
gone over 70 batches / 122 with 93.7428571429% train accuracy and 0.203435451848 loss in 281.451982975s
gone over 75 batches / 122 with 93.7333333333% train accuracy and 0.200402170626 loss in 313.183472872s
gone over 80 batches / 122 with 93.875% train accuracy and 0.196672365189 loss in 325.395190954s
gone over 85 batches / 122 with 93.9294117647% train accuracy and 0.193480199589 loss in 343.068363905s
gone over 90 batches / 122 with 94.0444444444% train accuracy and 0.188975807826 loss in 357.789163828s
gone over 95 batches / 122 with 93.9157894737% train accuracy and 0.192357122923 loss in 378.615309954s
gone over 100 batches / 122 with 93.9% train accuracy and 0.193645021915 loss in 388.674197912s
gone over 105 batches / 122 with 93.9619047619% train accuracy and 0.191277303151 loss in 409.183046818s
gone over 110 batches / 122 with 93.9636363636% train accuracy and 0.190706702579 loss in 433.660067797s
gone over 115 batches / 122 with 94.0347826087% train accuracy and 0.189275300565 loss in 444.166193962s
gone over 120 batches / 122 with 94.0666666667% train accuracy and 0.189106331746 loss in 457.806424856s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  2  , 663.48502 ,    0.188758    ,   94.050570   %,   0.548387   ,  84.288194  %

########## epoch #3 ##########
gone over 5 batches / 122 with 97.6% train accuracy and 0.0943726806641 loss in 51.1856589317s
gone over 10 batches / 122 with 98.4% train accuracy and 0.0654598808289 loss in 62.7166728973s
gone over 15 batches / 122 with 98.6666666667% train accuracy and 0.0643570747375 loss in 94.3147978783s
gone over 20 batches / 122 with 98.4% train accuracy and 0.0687509050369 loss in 114.274423838s
gone over 25 batches / 122 with 98.48% train accuracy and 0.0676926956177 loss in 125.426309824s
gone over 30 batches / 122 with 98.4% train accuracy and 0.070458621343 loss in 168.292708874s
gone over 35 batches / 122 with 98.4% train accuracy and 0.0755323979514 loss in 180.221062899s
gone over 40 batches / 122 with 98.25% train accuracy and 0.079599770546 loss in 191.980064869s
gone over 45 batches / 122 with 98.2666666667% train accuracy and 0.0799736501906 loss in 203.775131941s
gone over 50 batches / 122 with 98.32% train accuracy and 0.0765046016693 loss in 219.403825998s
gone over 55 batches / 122 with 98.1818181818% train accuracy and 0.0803938283053 loss in 229.57107091s
gone over 60 batches / 122 with 98.0666666667% train accuracy and 0.0822018376986 loss in 260.78320694s
gone over 65 batches / 122 with 98.1230769231% train accuracy and 0.0796221845333 loss in 271.424676895s
gone over 70 batches / 122 with 98.1142857143% train accuracy and 0.0797837840489 loss in 287.748370886s
gone over 75 batches / 122 with 98.1866666667% train accuracy and 0.0790825912476 loss in 299.632736921s
gone over 80 batches / 122 with 98.075% train accuracy and 0.080674708128 loss in 319.988236904s
gone over 85 batches / 122 with 98.0705882353% train accuracy and 0.0803797769547 loss in 333.893250942s
gone over 90 batches / 122 with 98.1777777778% train accuracy and 0.0771359488699 loss in 353.95739603s
gone over 95 batches / 122 with 98.1894736842% train accuracy and 0.0762444233141 loss in 370.86102581s
gone over 100 batches / 122 with 98.2% train accuracy and 0.0760008825302 loss in 396.463548899s
gone over 105 batches / 122 with 98.2095238095% train accuracy and 0.0770342516672 loss in 406.198997974s
gone over 110 batches / 122 with 98.2545454545% train accuracy and 0.0763013628613 loss in 434.360504866s
gone over 115 batches / 122 with 98.3130434783% train accuracy and 0.0745065300154 loss in 446.091262817s
gone over 120 batches / 122 with 98.2166666667% train accuracy and 0.074618599693 loss in 464.538609982s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  3  , 631.63935 ,    0.074292    ,   98.215171   %,   0.362863   ,  90.190972  %

########## epoch #4 ##########
gone over 5 batches / 122 with 98.8% train accuracy and 0.0378028831482 loss in 52.3945169449s
gone over 10 batches / 122 with 98.8% train accuracy and 0.0469151744843 loss in 71.6840231419s
gone over 15 batches / 122 with 98.9333333333% train accuracy and 0.0438323256175 loss in 84.1387269497s
gone over 20 batches / 122 with 98.6% train accuracy and 0.057618386507 loss in 103.037132025s
gone over 25 batches / 122 with 98.88% train accuracy and 0.0485399402618 loss in 115.198136091s
gone over 30 batches / 122 with 98.8% train accuracy and 0.049893438975 loss in 133.804301023s
gone over 35 batches / 122 with 98.9142857143% train accuracy and 0.0469306539808 loss in 145.514219999s
gone over 40 batches / 122 with 98.9% train accuracy and 0.0470074651241 loss in 164.028748989s
gone over 45 batches / 122 with 98.8888888889% train accuracy and 0.0506714433034 loss in 185.784976006s
gone over 50 batches / 122 with 98.72% train accuracy and 0.0543433137894 loss in 212.264254093s
gone over 55 batches / 122 with 98.7636363636% train accuracy and 0.0519293511131 loss in 228.315101147s
gone over 60 batches / 122 with 98.8% train accuracy and 0.0511845709483 loss in 239.152672052s
gone over 65 batches / 122 with 98.8615384615% train accuracy and 0.0494876312109 loss in 269.541119099s
gone over 70 batches / 122 with 98.8285714286% train accuracy and 0.049540030207 loss in 280.747277975s
gone over 75 batches / 122 with 98.8266666667% train accuracy and 0.0487926719666 loss in 302.498863935s
gone over 80 batches / 122 with 98.85% train accuracy and 0.0473064291477 loss in 319.012449026s
gone over 85 batches / 122 with 98.8941176471% train accuracy and 0.0482437442331 loss in 343.537022114s
gone over 90 batches / 122 with 98.9111111111% train accuracy and 0.048064359453 loss in 353.660841942s
gone over 95 batches / 122 with 98.9052631579% train accuracy and 0.047927634189 loss in 385.031017065s
gone over 100 batches / 122 with 98.82% train accuracy and 0.0502414834976 loss in 398.099518061s
gone over 105 batches / 122 with 98.6857142857% train accuracy and 0.0529842478434 loss in 442.259896994s
gone over 110 batches / 122 with 98.6363636364% train accuracy and 0.0553672770587 loss in 455.523309946s
gone over 115 batches / 122 with 98.6260869565% train accuracy and 0.0563021096769 loss in 466.313609123s
gone over 120 batches / 122 with 98.6166666667% train accuracy and 0.0562313314279 loss in 475.759075165s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  4  , 630.08106 ,    0.055859    ,   98.628326   %,   0.483325   ,  87.500000  %

########## epoch #5 ##########
gone over 5 batches / 122 with 98.8% train accuracy and 0.0283852329254 loss in 46.9602870941s
gone over 10 batches / 122 with 99.2% train accuracy and 0.0308938102722 loss in 56.6702141762s
gone over 15 batches / 122 with 99.2% train accuracy and 0.0418443323771 loss in 89.9522950649s
gone over 20 batches / 122 with 99.3% train accuracy and 0.0387739357948 loss in 102.359225035s
gone over 25 batches / 122 with 99.2% train accuracy and 0.0360754634857 loss in 130.669090033s
gone over 30 batches / 122 with 99.0666666667% train accuracy and 0.0366114953359 loss in 143.654740095s
gone over 35 batches / 122 with 99.0857142857% train accuracy and 0.0376523643221 loss in 169.673540115s
gone over 40 batches / 122 with 99.1% train accuracy and 0.0374227041006 loss in 179.423356056s
gone over 45 batches / 122 with 99.1555555556% train accuracy and 0.0353216443592 loss in 205.788101196s
gone over 50 batches / 122 with 99.24% train accuracy and 0.0330744761467 loss in 218.163910151s
gone over 55 batches / 122 with 99.2% train accuracy and 0.0339235133258 loss in 230.904901028s
gone over 60 batches / 122 with 99.1666666667% train accuracy and 0.0343519551754 loss in 241.188127995s
gone over 65 batches / 122 with 99.1384615385% train accuracy and 0.0365020227432 loss in 276.925844193s
gone over 70 batches / 122 with 99.1428571429% train accuracy and 0.0355297145162 loss in 287.562146187s
gone over 75 batches / 122 with 99.12% train accuracy and 0.0359852729162 loss in 309.996407986s
gone over 80 batches / 122 with 99.05% train accuracy and 0.0362548614144 loss in 325.914201021s
gone over 85 batches / 122 with 99.1058823529% train accuracy and 0.0347336683273 loss in 341.253992081s
gone over 90 batches / 122 with 99.0666666667% train accuracy and 0.0363831091987 loss in 351.353140116s
gone over 95 batches / 122 with 99.0947368421% train accuracy and 0.0353472880313 loss in 366.085976124s
gone over 100 batches / 122 with 98.98% train accuracy and 0.0414071204185 loss in 375.946328163s
gone over 105 batches / 122 with 98.8761904762% train accuracy and 0.0454847998846 loss in 407.782132149s
gone over 110 batches / 122 with 98.7636363636% train accuracy and 0.0481461437399 loss in 418.166769028s
gone over 115 batches / 122 with 98.7304347826% train accuracy and 0.047845420713 loss in 435.421967983s
gone over 120 batches / 122 with 98.7333333333% train accuracy and 0.0480133962234 loss in 447.865105152s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  5  , 597.42439 ,    0.047662    ,   98.744009   %,   0.423323   ,  90.017361  %

########## epoch #6 ##########
gone over 5 batches / 122 with 100.0% train accuracy and 0.010882724762 loss in 60.8836350441s
gone over 10 batches / 122 with 99.8% train accuracy and 0.0139256985188 loss in 70.8576321602s
gone over 15 batches / 122 with 99.8666666667% train accuracy and 0.0107556859652 loss in 116.626080036s
gone over 20 batches / 122 with 99.6% train accuracy and 0.0216737033129 loss in 128.923745155s
gone over 25 batches / 122 with 99.52% train accuracy and 0.0218316872597 loss in 152.997848034s
gone over 30 batches / 122 with 99.4666666667% train accuracy and 0.0216523810228 loss in 168.275902987s
gone over 35 batches / 122 with 99.4857142857% train accuracy and 0.0226280853408 loss in 178.066233158s
gone over 40 batches / 122 with 99.55% train accuracy and 0.0213697485924 loss in 189.865112066s
gone over 45 batches / 122 with 99.4666666667% train accuracy and 0.0244937027825 loss in 202.898789167s
gone over 50 batches / 122 with 99.4% train accuracy and 0.0283618227959 loss in 214.536457062s
gone over 55 batches / 122 with 99.3454545455% train accuracy and 0.0293243273822 loss in 227.258630991s
gone over 60 batches / 122 with 99.3333333333% train accuracy and 0.0288017748992 loss in 269.348742962s
gone over 65 batches / 122 with 99.3230769231% train accuracy and 0.0287256422043 loss in 280.444323063s
gone over 70 batches / 122 with 99.2857142857% train accuracy and 0.0304276833534 loss in 304.048017979s
gone over 75 batches / 122 with 99.2266666667% train accuracy and 0.0309470827103 loss in 317.590481043s
gone over 80 batches / 122 with 99.225% train accuracy and 0.0302412909865 loss in 335.004064083s
gone over 85 batches / 122 with 99.2235294118% train accuracy and 0.0322492237652 loss in 345.282498121s
gone over 90 batches / 122 with 99.1555555556% train accuracy and 0.0339563634661 loss in 359.851971149s
gone over 95 batches / 122 with 99.0947368421% train accuracy and 0.0344108940928 loss in 376.769538164s
gone over 100 batches / 122 with 99.08% train accuracy and 0.0340130083084 loss in 397.671830177s
gone over 105 batches / 122 with 99.1238095238% train accuracy and 0.0330020211992 loss in 413.144927025s
gone over 110 batches / 122 with 99.1272727273% train accuracy and 0.033189104557 loss in 441.790627956s
gone over 115 batches / 122 with 99.1304347826% train accuracy and 0.0329425441908 loss in 449.960119009s
gone over 120 batches / 122 with 99.0833333333% train accuracy and 0.0341650930246 loss in 461.119266033s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  6  , 620.96349 ,    0.033914    ,   99.091059   %,   0.339965   ,  91.493056  %

########## epoch #7 ##########
gone over 5 batches / 122 with 100.0% train accuracy and 0.0226112575531 loss in 57.7659811974s
gone over 10 batches / 122 with 99.6% train accuracy and 0.0222316699028 loss in 68.8426351547s
gone over 15 batches / 122 with 99.4666666667% train accuracy and 0.0251799414953 loss in 90.1223139763s
gone over 20 batches / 122 with 99.4% train accuracy and 0.0241872799397 loss in 100.529549122s
gone over 25 batches / 122 with 99.44% train accuracy and 0.0228122039795 loss in 121.020227194s
gone over 30 batches / 122 with 99.4666666667% train accuracy and 0.0215187559128 loss in 140.070976973s
gone over 35 batches / 122 with 99.4857142857% train accuracy and 0.0200657550267 loss in 157.7577672s
gone over 40 batches / 122 with 99.55% train accuracy and 0.0185190141201 loss in 176.637034178s
gone over 45 batches / 122 with 99.4222222222% train accuracy and 0.0265398840374 loss in 196.630417109s
gone over 50 batches / 122 with 99.44% train accuracy and 0.0255599072456 loss in 216.239541054s
gone over 55 batches / 122 with 99.4181818182% train accuracy and 0.0267469228398 loss in 235.912317991s
gone over 60 batches / 122 with 99.3666666667% train accuracy and 0.0270518215895 loss in 247.984920979s
gone over 65 batches / 122 with 99.3846153846% train accuracy and 0.0260889690473 loss in 263.439355135s
gone over 70 batches / 122 with 99.4% train accuracy and 0.0259568702153 loss in 288.355125189s
gone over 75 batches / 122 with 99.4133333333% train accuracy and 0.0251358194987 loss in 302.776138067s
gone over 80 batches / 122 with 99.425% train accuracy and 0.0246932088137 loss in 322.308751106s
gone over 85 batches / 122 with 99.4117647059% train accuracy and 0.02450963974 loss in 333.578623056s
gone over 90 batches / 122 with 99.3333333333% train accuracy and 0.0259313614104 loss in 359.477321148s
gone over 95 batches / 122 with 99.3263157895% train accuracy and 0.0256399189798 loss in 376.09555006s
gone over 100 batches / 122 with 99.34% train accuracy and 0.0252888791084 loss in 402.052597046s
gone over 105 batches / 122 with 99.3523809524% train accuracy and 0.0245177730379 loss in 411.430628061s
gone over 110 batches / 122 with 99.3454545455% train accuracy and 0.0238486228423 loss in 428.272957087s
gone over 115 batches / 122 with 99.3217391304% train accuracy and 0.0242390332429 loss in 439.377087116s
gone over 120 batches / 122 with 99.2833333333% train accuracy and 0.0259677066803 loss in 453.074189186s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  7  , 613.32447 ,    0.025778    ,   99.289374   %,   0.396396   ,  90.277778  %

########## epoch #8 ##########
gone over 5 batches / 122 with 100.0% train accuracy and 0.00617830848694 loss in 57.2936489582s
gone over 10 batches / 122 with 99.8% train accuracy and 0.033812417984 loss in 67.7136719227s
gone over 15 batches / 122 with 99.3333333333% train accuracy and 0.0339124422073 loss in 111.000378847s
gone over 20 batches / 122 with 99.3% train accuracy and 0.0287507488728 loss in 122.672375917s
gone over 25 batches / 122 with 99.44% train accuracy and 0.0239132616043 loss in 134.883167028s
gone over 30 batches / 122 with 99.5333333333% train accuracy and 0.0205042478244 loss in 146.465276003s
gone over 35 batches / 122 with 99.4285714286% train accuracy and 0.0218158963067 loss in 175.153175831s
gone over 40 batches / 122 with 99.5% train accuracy and 0.0202537683249 loss in 185.279191971s
gone over 45 batches / 122 with 99.4666666667% train accuracy and 0.0212723439535 loss in 199.77529192s
gone over 50 batches / 122 with 99.52% train accuracy and 0.0193625041962 loss in 211.939621925s
gone over 55 batches / 122 with 99.4909090909% train accuracy and 0.0203176452463 loss in 239.329201937s
gone over 60 batches / 122 with 99.4666666667% train accuracy and 0.0217925550938 loss in 248.57097888s
gone over 65 batches / 122 with 99.4769230769% train accuracy and 0.0218519955415 loss in 274.875420809s
gone over 70 batches / 122 with 99.4285714286% train accuracy and 0.0230070148877 loss in 289.560585022s
gone over 75 batches / 122 with 99.4133333333% train accuracy and 0.0225297955831 loss in 316.713163853s
gone over 80 batches / 122 with 99.4% train accuracy and 0.0224156712294 loss in 329.037328959s
gone over 85 batches / 122 with 99.4352941176% train accuracy and 0.0212988493302 loss in 341.41256094s
gone over 90 batches / 122 with 99.4222222222% train accuracy and 0.02097071192 loss in 375.637239933s
gone over 95 batches / 122 with 99.3894736842% train accuracy and 0.0223230797868 loss in 389.084723949s
gone over 100 batches / 122 with 99.38% train accuracy and 0.0225666304827 loss in 410.355067015s
gone over 105 batches / 122 with 99.3714285714% train accuracy and 0.0244785062018 loss in 422.05713892s
gone over 110 batches / 122 with 99.3636363636% train accuracy and 0.024403745066 loss in 438.395030975s
gone over 115 batches / 122 with 99.3913043478% train accuracy and 0.0236716359387 loss in 450.218619823s
gone over 120 batches / 122 with 99.4% train accuracy and 0.0230241621534 loss in 458.804270983s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  8  , 626.56715 ,    0.022862    ,   99.405057   %,   0.457546   ,  90.277778  %

########## epoch #9 ##########
gone over 5 batches / 122 with 100.0% train accuracy and 0.00402567672729 loss in 61.0228428841s
gone over 10 batches / 122 with 100.0% train accuracy and 0.0037245054245 loss in 72.7442948818s
gone over 15 batches / 122 with 99.8666666667% train accuracy and 0.0064342734019 loss in 100.598804951s
gone over 20 batches / 122 with 99.9% train accuracy and 0.00591025400162 loss in 111.324707031s
gone over 25 batches / 122 with 99.84% train accuracy and 0.00595714645386 loss in 137.578896046s
gone over 30 batches / 122 with 99.5333333333% train accuracy and 0.0145743754705 loss in 150.922851086s
gone over 35 batches / 122 with 99.4857142857% train accuracy and 0.0146431143624 loss in 167.622875929s
gone over 40 batches / 122 with 99.5% train accuracy and 0.0143736109734 loss in 178.999692917s
gone over 45 batches / 122 with 99.5555555556% train accuracy and 0.0135118115743 loss in 207.60067296s
gone over 50 batches / 122 with 99.48% train accuracy and 0.0156658856392 loss in 219.050289869s
gone over 55 batches / 122 with 99.4909090909% train accuracy and 0.0159099328301 loss in 245.248947859s
gone over 60 batches / 122 with 99.4666666667% train accuracy and 0.0162341001034 loss in 256.782594919s
gone over 65 batches / 122 with 99.4461538462% train accuracy and 0.0168144678703 loss in 280.942060947s
gone over 70 batches / 122 with 99.4571428571% train accuracy and 0.0159948613984 loss in 290.604956865s
gone over 75 batches / 122 with 99.4666666667% train accuracy and 0.0155302161535 loss in 317.56932807s
gone over 80 batches / 122 with 99.475% train accuracy and 0.0154696885943 loss in 328.640936852s
gone over 85 batches / 122 with 99.4352941176% train accuracy and 0.0177723130058 loss in 352.782459021s
gone over 90 batches / 122 with 99.4444444444% train accuracy and 0.0172691605356 loss in 365.421607971s
gone over 95 batches / 122 with 99.4736842105% train accuracy and 0.0165805237921 loss in 386.763143063s
gone over 100 batches / 122 with 99.48% train accuracy and 0.0165090451717 loss in 398.333385944s
gone over 105 batches / 122 with 99.5047619048% train accuracy and 0.0158867125284 loss in 412.157466888s
gone over 110 batches / 122 with 99.4909090909% train accuracy and 0.0163222393123 loss in 425.812228918s
gone over 115 batches / 122 with 99.4434782609% train accuracy and 0.0180114366697 loss in 437.82307601s
gone over 120 batches / 122 with 99.4% train accuracy and 0.0189530995289 loss in 460.384039879s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
  9  , 622.80427 ,    0.018817    ,   99.405057   %,   0.485108   ,  90.451389  %

########## epoch #10 ##########
gone over 5 batches / 122 with 98.8% train accuracy and 0.0438432312012 loss in 52.0523169041s
gone over 10 batches / 122 with 99.0% train accuracy and 0.0323960943222 loss in 61.2091870308s
gone over 15 batches / 122 with 98.8% train accuracy and 0.0358287029266 loss in 105.927715063s
gone over 20 batches / 122 with 99.1% train accuracy and 0.0306766148806 loss in 117.782997847s
gone over 25 batches / 122 with 99.04% train accuracy and 0.0296125847816 loss in 127.570257902s
gone over 30 batches / 122 with 99.2% train accuracy and 0.0258902315299 loss in 147.65712285s
gone over 35 batches / 122 with 99.2571428571% train accuracy and 0.0247733924048 loss in 174.606720924s
gone over 40 batches / 122 with 99.25% train accuracy and 0.0227811201811 loss in 185.828418016s
gone over 45 batches / 122 with 99.3333333333% train accuracy and 0.020772444725 loss in 207.819099903s
gone over 50 batches / 122 with 99.36% train accuracy and 0.0192871602058 loss in 225.475070953s
gone over 55 batches / 122 with 99.4181818182% train accuracy and 0.0178527245088 loss in 242.142344952s
gone over 60 batches / 122 with 99.3666666667% train accuracy and 0.0184997819265 loss in 265.444146872s
gone over 65 batches / 122 with 99.4153846154% train accuracy and 0.0173688652332 loss in 277.890537977s
gone over 70 batches / 122 with 99.3142857143% train accuracy and 0.01958603205 loss in 294.048826933s
gone over 75 batches / 122 with 99.3066666667% train accuracy and 0.0204606048584 loss in 305.567342043s
gone over 80 batches / 122 with 99.325% train accuracy and 0.0200935076475 loss in 315.846569061s
gone over 85 batches / 122 with 99.3647058824% train accuracy and 0.0190446888419 loss in 331.324939966s
gone over 90 batches / 122 with 99.3555555556% train accuracy and 0.0194968524509 loss in 357.080955029s
gone over 95 batches / 122 with 99.3473684211% train accuracy and 0.0193319763384 loss in 371.727459908s
gone over 100 batches / 122 with 99.36% train accuracy and 0.0187447857857 loss in 405.229137897s
gone over 105 batches / 122 with 99.3523809524% train accuracy and 0.0193491119657 loss in 414.813323975s
gone over 110 batches / 122 with 99.3636363636% train accuracy and 0.0190316524939 loss in 432.065897942s
gone over 115 batches / 122 with 99.3739130435% train accuracy and 0.0187016421194 loss in 445.647106886s
gone over 120 batches / 122 with 99.4% train accuracy and 0.0182617269754 loss in 456.538680077s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
 10  , 599.27599 ,    0.018128    ,   99.405057   %,   0.534251   ,  89.670139  %

########## epoch #11 ##########
gone over 5 batches / 122 with 99.2% train accuracy and 0.055540435791 loss in 43.4975891113s
gone over 10 batches / 122 with 99.6% train accuracy and 0.0306185445786 loss in 53.6686780453s
gone over 15 batches / 122 with 99.3333333333% train accuracy and 0.0263462022146 loss in 72.9153649807s
gone over 20 batches / 122 with 99.4% train accuracy and 0.0284935293198 loss in 90.5675041676s
gone over 25 batches / 122 with 99.36% train accuracy and 0.0279627285004 loss in 117.412739992s
gone over 30 batches / 122 with 99.4% train accuracy and 0.0274620370865 loss in 130.691370964s
gone over 35 batches / 122 with 99.4285714286% train accuracy and 0.0254458335468 loss in 154.322159052s
gone over 40 batches / 122 with 99.5% train accuracy and 0.0228352094293 loss in 164.983721018s
gone over 45 batches / 122 with 99.4666666667% train accuracy and 0.0217411483659 loss in 185.710288048s
gone over 50 batches / 122 with 99.52% train accuracy and 0.0197847962856 loss in 196.010584116s
gone over 55 batches / 122 with 99.5636363636% train accuracy and 0.0182480997172 loss in 224.712038994s
gone over 60 batches / 122 with 99.5666666667% train accuracy and 0.0178979722261 loss in 237.752639055s
gone over 65 batches / 122 with 99.5076923077% train accuracy and 0.0211259335371 loss in 271.93185401s
gone over 70 batches / 122 with 99.4571428571% train accuracy and 0.0215187499183 loss in 283.385761976s
gone over 75 batches / 122 with 99.44% train accuracy and 0.022241709137 loss in 306.021279097s
gone over 80 batches / 122 with 99.45% train accuracy and 0.0213967096806 loss in 318.808918953s
gone over 85 batches / 122 with 99.4588235294% train accuracy and 0.0208682176927 loss in 341.8791821s
gone over 90 batches / 122 with 99.4222222222% train accuracy and 0.0219255942239 loss in 351.599430084s
gone over 95 batches / 122 with 99.4105263158% train accuracy and 0.0218564328143 loss in 379.340239048s
gone over 100 batches / 122 with 99.38% train accuracy and 0.02201029706 loss in 391.359411001s
gone over 105 batches / 122 with 99.3523809524% train accuracy and 0.0221264588038 loss in 403.582332134s
gone over 110 batches / 122 with 99.2909090909% train accuracy and 0.0250510289452 loss in 414.339213133s
gone over 115 batches / 122 with 99.2869565217% train accuracy and 0.0255498007899 loss in 440.360013008s
gone over 120 batches / 122 with 99.2833333333% train accuracy and 0.0253611858686 loss in 450.045047045s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
 11  , 609.71947 ,    0.025617    ,   99.256321   %,   0.368867   ,  91.666667  %

########## epoch #12 ##########
gone over 5 batches / 122 with 99.6% train accuracy and 0.0184803910255 loss in 51.2084019184s
gone over 10 batches / 122 with 99.6% train accuracy and 0.0179615414143 loss in 63.2905569077s
gone over 15 batches / 122 with 99.4666666667% train accuracy and 0.0184321681658 loss in 89.1280839443s
gone over 20 batches / 122 with 99.3% train accuracy and 0.017696333766 loss in 100.528455973s
gone over 25 batches / 122 with 99.28% train accuracy and 0.0181502528191 loss in 120.344791889s
gone over 30 batches / 122 with 99.2666666667% train accuracy and 0.0200379119714 loss in 130.775542021s
gone over 35 batches / 122 with 99.2571428571% train accuracy and 0.0210238562311 loss in 156.233868837s
gone over 40 batches / 122 with 99.35% train accuracy and 0.0185694901347 loss in 169.006426811s
gone over 45 batches / 122 with 99.4222222222% train accuracy and 0.0171173955599 loss in 204.174158812s
gone over 50 batches / 122 with 99.44% train accuracy and 0.0163619960308 loss in 215.57614398s
gone over 55 batches / 122 with 99.4545454545% train accuracy and 0.0168472549699 loss in 237.838734865s
gone over 60 batches / 122 with 99.4666666667% train accuracy and 0.016558869799 loss in 249.803103924s
gone over 65 batches / 122 with 99.5076923077% train accuracy and 0.0153736099463 loss in 277.559292793s
gone over 70 batches / 122 with 99.4857142857% train accuracy and 0.0153492199693 loss in 289.727549791s
gone over 75 batches / 122 with 99.4666666667% train accuracy and 0.0155481848717 loss in 319.3180058s
gone over 80 batches / 122 with 99.475% train accuracy and 0.0149701066911 loss in 330.943166971s
gone over 85 batches / 122 with 99.4352941176% train accuracy and 0.0155982179922 loss in 352.268993855s
gone over 90 batches / 122 with 99.3555555556% train accuracy and 0.0168189286921 loss in 365.485665798s
gone over 95 batches / 122 with 99.3473684211% train accuracy and 0.017228605948 loss in 393.286961794s
gone over 100 batches / 122 with 99.32% train accuracy and 0.0172824543715 loss in 403.652122021s
gone over 105 batches / 122 with 99.3523809524% train accuracy and 0.0165835286776 loss in 435.536384821s
gone over 110 batches / 122 with 99.3454545455% train accuracy and 0.0166821758314 loss in 448.766119003s
gone over 115 batches / 122 with 99.3565217391% train accuracy and 0.0161781107239 loss in 459.288177967s
gone over 120 batches / 122 with 99.35% train accuracy and 0.0160011103352 loss in 468.873902798s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
 12  , 651.68833 ,    0.015876    ,   99.355478   %,   0.589555   ,  88.194444  %

########## epoch #13 ##########
gone over 5 batches / 122 with 100.0% train accuracy and 0.00486979675293 loss in 47.3025090694s
gone over 10 batches / 122 with 99.6% train accuracy and 0.00829518222809 loss in 57.9899098873s
gone over 15 batches / 122 with 99.7333333333% train accuracy and 0.00737290366491 loss in 102.586076021s
gone over 20 batches / 122 with 99.8% train accuracy and 0.00574647033215 loss in 113.161416054s
gone over 25 batches / 122 with 99.84% train accuracy and 0.00473082265854 loss in 132.302550077s
gone over 30 batches / 122 with 99.8% train accuracy and 0.00606147281329 loss in 143.013253927s
gone over 35 batches / 122 with 99.6571428571% train accuracy and 0.00864155217579 loss in 168.365653992s
gone over 40 batches / 122 with 99.6% train accuracy and 0.00963304227591 loss in 180.330250025s
gone over 45 batches / 122 with 99.6444444444% train accuracy and 0.00873837253782 loss in 190.424566031s
gone over 50 batches / 122 with 99.64% train accuracy and 0.00856745409966 loss in 202.929450035s
gone over 55 batches / 122 with 99.6363636364% train accuracy and 0.00856419424577 loss in 235.703886032s
gone over 60 batches / 122 with 99.6333333333% train accuracy and 0.00846177927653 loss in 247.193258047s
gone over 65 batches / 122 with 99.6307692308% train accuracy and 0.00887333631516 loss in 273.479636908s
gone over 70 batches / 122 with 99.6285714286% train accuracy and 0.00985344815254 loss in 294.236617088s
gone over 75 batches / 122 with 99.6% train accuracy and 0.00999379781087 loss in 304.63518405s
gone over 80 batches / 122 with 99.525% train accuracy and 0.0112778722048 loss in 329.753211021s
gone over 85 batches / 122 with 99.5529411765% train accuracy and 0.0107286730374 loss in 343.006474972s
gone over 90 batches / 122 with 99.5333333333% train accuracy and 0.0113182639016 loss in 371.499829054s
gone over 95 batches / 122 with 99.5368421053% train accuracy and 0.0110985998856 loss in 386.343813896s
gone over 100 batches / 122 with 99.5% train accuracy and 0.0121040494442 loss in 404.162054062s
gone over 105 batches / 122 with 99.5238095238% train accuracy and 0.011808019411 loss in 416.995193005s
gone over 110 batches / 122 with 99.5272727273% train accuracy and 0.0122340722084 loss in 431.521213055s
gone over 115 batches / 122 with 99.5304347826% train accuracy and 0.0127327207068 loss in 443.412645102s
gone over 120 batches / 122 with 99.5166666667% train accuracy and 0.0132991353472 loss in 458.055885077s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
 13  , 612.78757 ,    0.013192    ,   99.520740   %,   0.641529   ,  87.500000  %

########## epoch #14 ##########
gone over 5 batches / 122 with 99.2% train accuracy and 0.0181025133133 loss in 57.608839035s
gone over 10 batches / 122 with 99.4% train accuracy and 0.0121221737862 loss in 68.4203879833s
gone over 15 batches / 122 with 99.6% train accuracy and 0.00952424017588 loss in 103.502072811s
gone over 20 batches / 122 with 99.6% train accuracy and 0.00887355685234 loss in 116.729573965s
gone over 25 batches / 122 with 99.6% train accuracy and 0.00819984035492 loss in 156.558315992s
gone over 30 batches / 122 with 99.6% train accuracy and 0.00786212587357 loss in 166.30538702s
gone over 35 batches / 122 with 99.6571428571% train accuracy and 0.00696066461291 loss in 177.691323996s
gone over 40 batches / 122 with 99.65% train accuracy and 0.00721812540293 loss in 188.441710949s
gone over 45 batches / 122 with 99.6444444444% train accuracy and 0.00706608290142 loss in 203.941279888s
gone over 50 batches / 122 with 99.64% train accuracy and 0.00743115801811 loss in 213.60191083s
gone over 55 batches / 122 with 99.6% train accuracy and 0.00938965697722 loss in 234.402060032s
gone over 60 batches / 122 with 99.6333333333% train accuracy and 0.00897184383869 loss in 251.011188984s
gone over 65 batches / 122 with 99.6% train accuracy and 0.00942837542754 loss in 292.292625904s
gone over 70 batches / 122 with 99.5714285714% train accuracy and 0.0100287413257 loss in 303.518721819s
gone over 75 batches / 122 with 99.6% train accuracy and 0.00955657466253 loss in 330.038251877s
gone over 80 batches / 122 with 99.525% train accuracy and 0.0151347647011 loss in 342.560992956s
gone over 85 batches / 122 with 99.5294117647% train accuracy and 0.0151765415248 loss in 352.681206942s
gone over 90 batches / 122 with 99.5333333333% train accuracy and 0.0149557782544 loss in 365.092432022s
gone over 95 batches / 122 with 99.5578947368% train accuracy and 0.0144920233174 loss in 398.094436884s
gone over 100 batches / 122 with 99.58% train accuracy and 0.0138894225359 loss in 408.611405849s
gone over 105 batches / 122 with 99.5619047619% train accuracy and 0.0138865015166 loss in 429.285283804s
gone over 110 batches / 122 with 99.5454545455% train accuracy and 0.0144036629633 loss in 442.481666803s
gone over 115 batches / 122 with 99.5304347826% train accuracy and 0.0144553976681 loss in 455.889067888s
gone over 120 batches / 122 with 99.5% train accuracy and 0.0155953013301 loss in 467.159570932s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
 14  , 634.08614 ,    0.015824    ,   99.487688   %,   0.657794   ,  87.586806  %

########## epoch #15 ##########
gone over 5 batches / 122 with 98.8% train accuracy and 0.0331966338158 loss in 47.9743318558s
gone over 10 batches / 122 with 99.0% train accuracy and 0.0265950791836 loss in 58.5256669521s
gone over 15 batches / 122 with 98.9333333333% train accuracy and 0.0221612375577 loss in 90.0743770599s
gone over 20 batches / 122 with 99.2% train accuracy and 0.0170288800001 loss in 103.777432919s
gone over 25 batches / 122 with 99.36% train accuracy and 0.0143042464256 loss in 127.994214058s
gone over 30 batches / 122 with 99.4% train accuracy and 0.0130103046894 loss in 137.642119884s
gone over 35 batches / 122 with 99.4285714286% train accuracy and 0.0117619718143 loss in 176.270441055s
gone over 40 batches / 122 with 99.5% train accuracy and 0.0112096611857 loss in 188.085856915s
gone over 45 batches / 122 with 99.4222222222% train accuracy and 0.012204852793 loss in 215.893265009s
gone over 50 batches / 122 with 99.44% train accuracy and 0.0118596639156 loss in 228.528462887s
gone over 55 batches / 122 with 99.4909090909% train accuracy and 0.0110337654027 loss in 239.509209871s
gone over 60 batches / 122 with 99.5% train accuracy and 0.0108088084459 loss in 251.985812902s
gone over 65 batches / 122 with 99.5076923077% train accuracy and 0.0104610508772 loss in 278.119289875s
gone over 70 batches / 122 with 99.5428571429% train accuracy and 0.0101507507392 loss in 291.967334986s
gone over 75 batches / 122 with 99.5466666667% train accuracy and 0.00989609829585 loss in 313.854254961s
gone over 80 batches / 122 with 99.525% train accuracy and 0.0102283888757 loss in 324.454007864s
gone over 85 batches / 122 with 99.5294117647% train accuracy and 0.00984208339803 loss in 342.862607002s
gone over 90 batches / 122 with 99.4444444444% train accuracy and 0.0114485297468 loss in 368.954321861s
gone over 95 batches / 122 with 99.4526315789% train accuracy and 0.0112155824711 loss in 377.815193892s
gone over 100 batches / 122 with 99.48% train accuracy and 0.0108344043016 loss in 404.746841908s
gone over 105 batches / 122 with 99.5047619048% train accuracy and 0.0103425821804 loss in 415.021172047s
gone over 110 batches / 122 with 99.4545454545% train accuracy and 0.0120297830972 loss in 432.530701876s
gone over 115 batches / 122 with 99.4608695652% train accuracy and 0.0117583876278 loss in 454.887604952s
gone over 120 batches / 122 with 99.4833333333% train accuracy and 0.0113576032519 loss in 466.262851954s
=========================
epoch, epoch time, train avg. loss, train accuracy, dev avg. loss, dev accuracy
 15  , 619.96281 ,    0.011266    ,   99.487688   %,   0.614178   ,  88.454861  %

